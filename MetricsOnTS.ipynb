{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn.metrics.pairwise import pairwise_distances_chunked\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_of_labels(n_labels, n_samples):\n",
    "    \"\"\"Check that number of labels are valid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_labels : int\n",
    "        Number of labels.\n",
    "\n",
    "    n_samples : int\n",
    "        Number of samples.\n",
    "    \"\"\"\n",
    "    if not 1 < n_labels < n_samples:\n",
    "        raise ValueError(\n",
    "            \"Number of labels is %d. Valid values are 2 to n_samples - 1 (inclusive)\"\n",
    "            % n_labels\n",
    "        )\n",
    "\n",
    "def davies_bouldin_score(X, labels,centroids):\n",
    "    \"\"\"Compute the Davies-Bouldin score.\n",
    "\n",
    "    The score is defined as the average similarity measure of each cluster with\n",
    "    its most similar cluster, where similarity is the ratio of within-cluster\n",
    "    distances to between-cluster distances. Thus, clusters which are farther\n",
    "    apart and less dispersed will result in a better score.\n",
    "\n",
    "    The minimum score is zero, with lower values indicating better clustering.\n",
    "\n",
    "    Read more in the :ref:`User Guide <davies-bouldin_index>`.\n",
    "\n",
    "    .. versionadded:: 0.20\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        A list of ``n_features``-dimensional data points. Each row corresponds\n",
    "        to a single data point.\n",
    "\n",
    "    labels : array-like of shape (n_samples,)\n",
    "        Predicted labels for each sample.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        The resulting Davies-Bouldin score.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Davies, David L.; Bouldin, Donald W. (1979).\n",
    "       `\"A Cluster Separation Measure\"\n",
    "       <https://ieeexplore.ieee.org/document/4766909>`__.\n",
    "       IEEE Transactions on Pattern Analysis and Machine Intelligence.\n",
    "       PAMI-1 (2): 224-227\n",
    "    \"\"\"\n",
    "    X, labels = check_X_y(X, labels)\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    n_samples, _ = X.shape\n",
    "    n_labels = len(le.classes_)\n",
    "    check_number_of_labels(n_labels, n_samples)\n",
    "\n",
    "    intra_dists = np.zeros(n_labels)\n",
    "    #centroids = np.zeros((n_labels, len(X[0])), dtype=float)\n",
    "    for k in range(n_labels):\n",
    "        cluster_k = _safe_indexing(X, labels == k)\n",
    "        #centroid = cluster_k.mean(axis=0)\n",
    "        #centroids[k] = centroid\n",
    "        intra_dists[k] = np.average(pairwise_distances(cluster_k, [centroids[k]]))\n",
    "\n",
    "    centroid_distances = pairwise_distances(centroids)\n",
    "\n",
    "    if np.allclose(intra_dists, 0) or np.allclose(centroid_distances, 0):\n",
    "        return 0.0\n",
    "\n",
    "    centroid_distances[centroid_distances == 0] = np.inf\n",
    "    combined_intra_dists = intra_dists[:, None] + intra_dists\n",
    "    scores = np.max(combined_intra_dists / centroid_distances, axis=1)\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/allPixelNDVIPoly.pickle', 'rb') as handle:\n",
    "    allPixelNDVIPoly3 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newResa3.pickle', 'rb') as handle:\n",
    "    newResa3 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/allPixelNDVIPoly4.pickle', 'rb') as handle:\n",
    "    allPixelNDVIPoly4 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newResa4.pickle', 'rb') as handle:\n",
    "    newResa4 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/allPixelNDVIPoly6.pickle', 'rb') as handle:\n",
    "    allPixelNDVIPoly6 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newResa6.pickle', 'rb') as handle:\n",
    "    newResa6 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/kluster_centroids_3_c2.pickle', 'rb') as handle:\n",
    "    centroids_3 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/kluster_centroids_4_c2.pickle', 'rb') as handle:\n",
    "    centroids_4 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/kluster_centroids_6_c2.pickle', 'rb') as handle:\n",
    "    centroids_6 = pickle.load(handle)\n",
    "\n",
    "num_cluster = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n",
      "1700\n"
     ]
    }
   ],
   "source": [
    "allPixelNDVIPoly3 = allPixelNDVIPoly3[(newResa3<=11000) & (newResa3 >= 4000),:]\n",
    "newResa3 = newResa3[(newResa3<=11000) & (newResa3 >= 4000)]\n",
    "\n",
    "allPixelNDVIPoly4 = allPixelNDVIPoly4[(newResa4<=11000) & (newResa4 >= 4000),:]\n",
    "newResa4 = newResa4[(newResa4<=11000) & (newResa4 >= 4000)]\n",
    "print(len(newResa4))\n",
    "\n",
    "allPixelNDVIPoly6 = allPixelNDVIPoly6[(newResa6<=11000) & (newResa6 >= 4000),:]\n",
    "newResa6 = newResa6[(newResa6<=11000) & (newResa6 >= 4000)]\n",
    "print(len(newResa6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means su tutto l'asse temporale \n",
    "\n",
    "km_one3 = TimeSeriesKMeans(n_clusters=num_cluster, metric=\"euclidean\", max_iter=100,random_state=0)\n",
    "y_pred_one3 = km_one3.fit_predict(allPixelNDVIPoly3)\n",
    "\n",
    "km_one4 = TimeSeriesKMeans(n_clusters=num_cluster, metric=\"euclidean\", max_iter=100,random_state=0)\n",
    "y_pred_one4 = km_one4.fit_predict(allPixelNDVIPoly4)\n",
    "\n",
    "km_one6 = TimeSeriesKMeans(n_clusters=num_cluster, metric=\"euclidean\", max_iter=100,random_state=0)\n",
    "y_pred_one6 = km_one6.fit_predict(allPixelNDVIPoly6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "1.4875373563042251\n",
      "1.4875373563042251\n"
     ]
    }
   ],
   "source": [
    "print(len(allPixelNDVIPoly3[y_pred_one3 == 0][0]))\n",
    "print(len(km_one3.cluster_centers_[0].ravel()))\n",
    "print(np.linalg.norm(allPixelNDVIPoly3[y_pred_one3 == 0][0] - km_one3.cluster_centers_[0].ravel()))\n",
    "print(dist.euclidean(allPixelNDVIPoly3[y_pred_one3 == 0][0],km_one3.cluster_centers_[0].ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancefromC = []\n",
    "centroids = []\n",
    "for cluster in range(0,num_cluster):\n",
    "    \n",
    "    #\n",
    "    ClusterTs = allPixelNDVIPoly3[y_pred_one3 == cluster]\n",
    "    centroids = np.tile(km_one3.cluster_centers_[cluster].ravel(),(ClusterTs.shape[0],1))\n",
    "    distancefromC.append(np.linalg.norm(ClusterTs - centroids,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533 938\n"
     ]
    }
   ],
   "source": [
    "print(len(distancefromC[0]),len(distancefromC[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coesione del TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster0\n",
      "0.3983831975975734\n",
      "0.23879895848444946\n",
      "cluster1\n",
      "0.2829296657076909\n",
      "0.10894201014921998\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(0,num_cluster):\n",
    "    print(\"cluster\"+str(cluster))\n",
    "    print(np.array(distancefromC[cluster]).mean())\n",
    "    print(np.array(distancefromC[cluster]).std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daviesâ€“Bouldin index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice dv del campo 3\n",
      "0.9182155745206129\n",
      "indice dv del campo 4\n",
      "0.6959551693977397\n",
      "indice dv del campo 6\n",
      "0.3561120797190385\n"
     ]
    }
   ],
   "source": [
    "#Rese 3 \n",
    "centroids = []\n",
    "for cluster in range(0,num_cluster):\n",
    "    centroids.append(km_one3.cluster_centers_[cluster].ravel())\n",
    "centroids = np.array(centroids)\n",
    "print(\"indice dv del campo\",3)\n",
    "print(davies_bouldin_score(allPixelNDVIPoly3,y_pred_one3,centroids))\n",
    "\n",
    "#Resa 4\n",
    "centroids = []\n",
    "for cluster in range(0,num_cluster):\n",
    "    centroids.append(km_one4.cluster_centers_[cluster].ravel())\n",
    "centroids = np.array(centroids)\n",
    "print(\"indice dv del campo\",4)\n",
    "print(davies_bouldin_score(allPixelNDVIPoly4,y_pred_one4,centroids))\n",
    "\n",
    "#Resa 6\n",
    "centroids = []\n",
    "for cluster in range(0,num_cluster):\n",
    "    centroids.append(km_one6.cluster_centers_[cluster].ravel())\n",
    "centroids = np.array(centroids)\n",
    "print(\"indice dv del campo\",6)\n",
    "print(davies_bouldin_score(allPixelNDVIPoly6,y_pred_one6,centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andiamo a utilizzare le metriche su tutti i cluster delle varie curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/kmeans_total_3_c2.pickle', 'rb') as handle:\n",
    "    kmeans_total3 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/kmeans_total_4_c2.pickle', 'rb') as handle:\n",
    "    kmeans_total4 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/kmeans_total_6_c2.pickle', 'rb') as handle:\n",
    "    kmeans_total6 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newSeries_total_3.pickle', 'rb') as handle:\n",
    "    newSeries_total_3 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newSeries_total_4.pickle', 'rb') as handle:\n",
    "    newSeries_total_4 = pickle.load(handle)\n",
    "\n",
    "with open('./pickles/newSeries_total_6.pickle', 'rb') as handle:\n",
    "    newSeries_total_6 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(NDVIpoly,kmeans_total,centroid,cluster):\n",
    "    ClusterTs = NDVIpoly[kmeans_total == cluster]\n",
    "    return np.linalg.norm(ClusterTs - np.tile(centroid,(ClusterTs.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coesione_3 = np.zeros((int(155/5),int(155/5),num_cluster))\n",
    "coesione_4 = np.zeros((int(155/5),int(155/5),num_cluster))\n",
    "coesione_6 = np.zeros((int(155/5),int(155/5),num_cluster))\n",
    "\n",
    "davisBouldin3 = np.zeros((int(155/5),int(155/5)))\n",
    "davisBouldin4 = np.zeros((int(155/5),int(155/5)))\n",
    "davisBouldin6 = np.zeros((int(155/5),int(155/5)))\n",
    "\n",
    "\n",
    "for x in range(0,int(155/5)):\n",
    "    for y in range(0,int(155/5)):\n",
    "        if(kmeans_total3[x,y] is not None):\n",
    "            centroid3 = []\n",
    "            centroid4 = []\n",
    "            centroid6 = []\n",
    "            for cluster in range(0,num_cluster):\n",
    "\n",
    "                centroid3.append(centroids_3[x,y,cluster])\n",
    "                centroid4.append(centroids_4[x,y,cluster])\n",
    "                centroid6.append(centroids_6[x,y,cluster])\n",
    "\n",
    "                \n",
    "                #Coesione Cluster (deviazione standard)\n",
    "                distancefromC3 = calculateDistance(newSeries_total_3[x,y],kmeans_total3[x,y],centroids_3[x,y,cluster],cluster)\n",
    "                distancefromC4 = calculateDistance(newSeries_total_4[x,y],kmeans_total4[x,y],centroids_4[x,y,cluster],cluster)\n",
    "                distancefromC6 = calculateDistance(newSeries_total_6[x,y],kmeans_total6[x,y],centroids_6[x,y,cluster],cluster)\n",
    "\n",
    "                coesione_3[x,y,cluster] = distancefromC3.std()\n",
    "                coesione_4[x,y,cluster] = distancefromC4.std()\n",
    "                coesione_6[x,y,cluster] = distancefromC6.std()\n",
    "\n",
    "            davisBouldin3[x,y] = davies_bouldin_score(newSeries_total_3[x,y],kmeans_total3[x,y],centroid3)\n",
    "            davisBouldin4[x,y] = davies_bouldin_score(newSeries_total_4[x,y],kmeans_total4[x,y],centroid4)\n",
    "            davisBouldin6[x,y] = davies_bouldin_score(newSeries_total_6[x,y],kmeans_total6[x,y],centroid6)\n",
    "        else:\n",
    "            continue\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
